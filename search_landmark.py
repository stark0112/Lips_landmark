import torch

# ëª¨ë¸ íŒŒì¼ ë¡œë“œ
full_model_path = "blazeface_full_best.pth"
full_model_state = torch.load(full_model_path, map_location="cpu")

# í™•ì¸í•  ë ˆì´ì–´ ëª©ë¡
layers_to_check = [
    "bbox_head.weight", "bbox_head.bias",
    "conf_head.weight", "conf_head.bias",
    "landmark_subnet.0.weight", "landmark_subnet.0.bias",
    "landmark_subnet.2.weight", "landmark_subnet.2.bias"
]


# ê° ë ˆì´ì–´ì˜ ê°’ ì¶œë ¥ (ìƒ˜í”Œ 5ê°œë§Œ)
print(f"ğŸ” {full_model_path} ë‚´ìš©:")
for layer in layers_to_check:
    if layer in full_model_state:
        layer_data = full_model_state[layer].numpy()
        sample_values = layer_data.flatten()[:20]  # ğŸ”¥ ìƒ˜í”Œ 5ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
        print(f"{layer} ê°’ (ìƒ˜í”Œ 5ê°œ):\n", sample_values, "\n")

    else:
        print(f"âŒ {layer} í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n")

import torch

# ëª¨ë¸ íŒŒì¼ ë¡œë“œ
celeba_model_path = "blazeface_celeba.pth"
celeba_model_state = torch.load(celeba_model_path, map_location="cpu")

# í™•ì¸í•  ë ˆì´ì–´ ëª©ë¡
layers_to_check = [
    "bbox_head.weight", "bbox_head.bias",
    "conf_head.weight", "conf_head.bias"
]

# ê° ë ˆì´ì–´ì˜ ê°’ ì¶œë ¥ (ìƒ˜í”Œ 5ê°œë§Œ)
print(f"ğŸ” {celeba_model_path} ë‚´ìš©:")
for layer in layers_to_check:
    if layer in celeba_model_state:
        layer_data = celeba_model_state[layer].numpy()
        sample_values = layer_data.flatten()[:20]  # ğŸ”¥ ìƒ˜í”Œ 5ê°œë§Œ ê°€ì ¸ì˜¤ê¸°
        print(f"{layer} ê°’ (ìƒ˜í”Œ 5ê°œ):\n", sample_values, "\n")
    else:
        print(f"âŒ {layer} í‚¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n")

'''
import torch

# ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ë¡œë“œ
model_path = "blazeface_full_best.pth"
state_dict = torch.load(model_path, map_location="cpu")

# âœ… ëª¨ë¸ì˜ í‚¤(ë ˆì´ì–´ ì´ë¦„) í™•ì¸
print("ğŸ“Œ ëª¨ë¸ì˜ state_dict í‚¤ ëª©ë¡:")
for key in state_dict.keys():
    print(key)

# âœ… íŠ¹ì • ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ í™•ì¸ (ì˜ˆ: bbox_headì˜ ì²« ë²ˆì§¸ Conv ë ˆì´ì–´)
if "bbox_head.weight" in state_dict:
    print("\nğŸ“Œ bbox_head.weight ê°€ì¤‘ì¹˜ ìƒ˜í”Œ:")
    print(state_dict["bbox_head.weight"])
'''

