import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import os
from PIL import Image
from tqdm import tqdm  # ğŸ”¹ tqdm ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ (ì§„í–‰ë¥  í‘œì‹œ)

# ğŸ”¹ Depthwise Separable Convolution ì •ì˜
class DepthwiseSeparableConv(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):
        super().__init__()
        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, 
                                   stride=stride, padding=kernel_size//2, groups=in_channels, bias=False)
        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU6(inplace=True)
    
    def forward(self, x):
        x = self.depthwise(x)
        x = self.pointwise(x)
        x = self.bn(x)
        return self.relu(x)

# ğŸ”¹ Inverted Residual Block (IRB) ì •ì˜
class InvertedResidualBlock(nn.Module):
    def __init__(self, in_channels, out_channels, expansion=6):
        super().__init__()
        hidden_dim = in_channels * expansion
        self.use_residual = in_channels == out_channels
        
        self.block = nn.Sequential(
            nn.Conv2d(in_channels, hidden_dim, kernel_size=1, bias=False),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU6(inplace=True),

            DepthwiseSeparableConv(hidden_dim, hidden_dim, stride=1),
            nn.BatchNorm2d(hidden_dim),
            nn.ReLU6(inplace=True),

            nn.Conv2d(hidden_dim, out_channels, kernel_size=1, bias=False),
            nn.BatchNorm2d(out_channels)
        )
    
    def forward(self, x):
        if self.use_residual:
            return x + self.block(x)  # Skip Connection ì ìš©
        else:
            return self.block(x)

# ğŸ”¹ ë„¤íŠ¸ì›Œí¬ ì •ì˜
class Lip3DLandmarkNet(nn.Module):
    def __init__(self):
        super().__init__()

        # ì´ˆê¸° ë‹¤ìš´ìƒ˜í”Œë§ ë‹¨ê³„
        self.conv1 = DepthwiseSeparableConv(3, 16, stride=2)  # 256 â†’ 128
        self.conv2 = DepthwiseSeparableConv(16, 32, stride=2) # 128 â†’ 64
        self.conv3 = DepthwiseSeparableConv(32, 64, stride=2) # 64 â†’ 32
        self.conv4 = DepthwiseSeparableConv(64, 128, stride=2) # 32 â†’ 16

        # IRB ë¸”ë¡ 6ê°œ ì ìš©
        self.irb1 = InvertedResidualBlock(128, 128)
        self.irb2 = InvertedResidualBlock(128, 128)
        self.irb3 = InvertedResidualBlock(128, 128)
        self.irb4 = InvertedResidualBlock(128, 256)
        self.irb5 = InvertedResidualBlock(256, 256)
        self.irb6 = InvertedResidualBlock(256, 256)

        # Global Average Pooling & FC Layer
        self.global_pool = nn.AdaptiveAvgPool2d(1)  # (B, C, H, W) â†’ (B, C, 1, 1)
        self.fc = nn.Linear(256, 120)  # 40ê°œì˜ (x, y, z) ì¢Œí‘œë¥¼ ì¶œë ¥

    def forward(self, x):
        x = self.conv1(x)
        x = self.conv2(x)
        x = self.conv3(x)
        x = self.conv4(x)

        x = self.irb1(x)
        x = self.irb2(x)
        x = self.irb3(x)
        x = self.irb4(x)
        x = self.irb5(x)
        x = self.irb6(x)

        x = self.global_pool(x)
        x = torch.flatten(x, 1)  # (B, 256, 1, 1) â†’ (B, 256)
        x = self.fc(x)  # (B, 120)

        return x.view(-1, 40, 3)  # (B, 40, 3) í˜•íƒœë¡œ ë³€í™˜ (x, y, z)

# 2ï¸âƒ£ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = Lip3DLandmarkNet().to(device)
model.load_state_dict(torch.load("best_lip_3d_landmark_model.pth", map_location=device))
model.eval()  # ğŸ”¹ ì¶”ë¡ (í…ŒìŠ¤íŠ¸) ëª¨ë“œë¡œ ë³€ê²½

# 3ï¸âƒ£ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ ì •ì˜
def preprocess_image(image_path):
    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    image = Image.open(image_path).convert("RGB")
    image = transform(image).unsqueeze(0)  # (1, 3, 256, 256) ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return image.to(device)

# 4ï¸âƒ£ ëœë“œë§ˆí¬ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_landmarks(image_path):
    image = preprocess_image(image_path)
    with torch.no_grad():
        landmarks = model(image).cpu().numpy()  # (1, 40, 3) í˜•íƒœ
    return landmarks[0]  # (40, 3)

# 5ï¸âƒ£ ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜
def visualize_landmarks(image_path, landmarks):
    image = Image.open(image_path)
    img_w, img_h = image.size  # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° ê°€ì ¸ì˜¤ê¸°

    # ëœë“œë§ˆí¬ ì¢Œí‘œ ë³€í™˜ (ì •ê·œí™” í•´ì œ)
    landmarks[:, 0] = (landmarks[:, 0] + 1) * (img_w / 2)  # x ì¢Œí‘œ ë³€í™˜
    landmarks[:, 1] = (landmarks[:, 1] + 1) * (img_h / 2)  # y ì¢Œí‘œ ë³€í™˜

    # ì´ë¯¸ì§€ ë° ëœë“œë§ˆí¬ í‘œì‹œ
    plt.imshow(image)
    plt.scatter(landmarks[:, 0], landmarks[:, 1], c='red', marker='o')
    plt.title("Predicted 3D Lip Landmarks (Projected to 2D)")
    plt.show()

# 6ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ë° ì‹œê°í™”
image_path = "test_lip_image.jpg"  # ğŸ”¹ í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ ê²½ë¡œ
predicted_landmarks = predict_landmarks(image_path)
visualize_landmarks(image_path, predicted_landmarks)