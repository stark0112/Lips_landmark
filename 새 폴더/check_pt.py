import torch

# âœ… ë°ì´í„° ë¡œë“œ
aug_data_path = "merged_data_celeba2_aug.pt"
augmented_data = torch.load(aug_data_path)

# âœ… ë°ì´í„°ì…‹ ê°œìˆ˜ ì¶œë ¥
print(f"âœ… ë°ì´í„°ì…‹ ê°œìˆ˜: {len(augmented_data)}ê°œ")

# âœ… ë°ì´í„° í˜•íƒœ í™•ì¸ (ì²« ë²ˆì§¸ ìƒ˜í”Œ)
first_sample = augmented_data[0]
print("\nâœ… ë°ì´í„° êµ¬ì¡° ì˜ˆì‹œ:")
print(f"  â”œâ”€â”€ ì´ë¯¸ì§€ ê²½ë¡œ: {first_sample[0]}")
print(f"  â”œâ”€â”€ Bounding Box: {first_sample[1]}")  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
print(f"  â””â”€â”€ ëœë“œë§ˆí¬ (ì •ê·œí™”ë¨): {first_sample[2]}")  # ëœë“œë§ˆí¬ ì¢Œí‘œ (ì •ê·œí™”ë¨)

# âœ… ë°ì´í„°ì…‹ ì¼ë¶€ ìƒ˜í”Œ ì¶œë ¥ (ë§ˆì§€ë§‰ 5ê°œ)
print("\nâœ… ë§ˆì§€ë§‰ 5ê°œ ìƒ˜í”Œ:")
for image_path, bbox, landmarks in augmented_data[-100:]:
    print(f"ğŸ“· ì´ë¯¸ì§€ ê²½ë¡œ: {image_path}")
    print(f"   â”œâ”€â”€ Bounding Box: {bbox}")
    print(f"   â””â”€â”€ ëœë“œë§ˆí¬: {landmarks[:6]} ... (ì´ {len(landmarks)}ê°œ)")
    print("-" * 80)
