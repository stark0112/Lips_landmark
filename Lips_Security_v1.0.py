import cv2
import mediapipe as mp
import numpy as np
import time
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean

# --- ì…ìˆ , ê¸°ì¤€ì  ì¸ë±ìŠ¤ ì„¤ì • (MediaPipe FaceMesh ê¸°ì¤€) ---
LIPS_IDX_40 = [
    61, 185, 40, 39, 37, 0, 267, 269, 270, 409,
    291, 375, 321, 405, 314, 17, 84, 181, 91, 146,
    78, 95, 88, 178, 87, 14, 317, 402, 318, 324,
    308, 415, 310, 311, 312, 13, 82, 81, 80, 191
]
EYE_LEFT_IDX = 33      # ì™¼ìª½ ëˆˆ
EYE_RIGHT_IDX = 263    # ì˜¤ë¥¸ìª½ ëˆˆ
NOSE_TIP_IDX = 1       # ì½” ë

# --- ì…ìˆ  3D ì •ê·œí™” í•¨ìˆ˜ ---
def normalize_lips_3d(points, ref_points):
    center = np.mean(points, axis=0)   # ì¤‘ì‹¬ ì •ë ¬
    points -= center

    # ì¢Œí‘œê³„ ì •ì˜ (xì¶•: ì…ê¼¬ë¦¬, yì¶•: ì… ìœ„ì•„ë˜, zì¶•: ìˆ˜ì§ ë°©í–¥)
    x_axis = points[10] - points[0]
    x_axis /= np.linalg.norm(x_axis)
    y_axis = points[29] - points[19]
    y_axis /= np.linalg.norm(y_axis)
    z_axis = np.cross(x_axis, y_axis)
    z_axis /= np.linalg.norm(z_axis)
    y_axis = np.cross(z_axis, x_axis)
    y_axis /= np.linalg.norm(y_axis)
    y_axis *= -1

    # íšŒì „ ì •ë ¬
    R = np.stack([x_axis, y_axis, z_axis], axis=1)
    points = points @ R

    # ëˆˆ-ì½” ì‚¬ì´ ê±°ë¦¬ë¡œ ìŠ¤ì¼€ì¼ ì •ê·œí™”
    eye_left = ref_points[EYE_LEFT_IDX]
    eye_right = ref_points[EYE_RIGHT_IDX]
    nose = ref_points[NOSE_TIP_IDX]
    scale = (np.linalg.norm(eye_left - eye_right) + np.linalg.norm(nose - (eye_left + eye_right)/2)) / 2
    if scale > 0:
        points /= scale
    return points

# --- ë°œí™” êµ¬ê°„ ì¶”ì¶œ (ì›€ì§ì„ì´ í° êµ¬ê°„ë§Œ ì¶”ì¶œ) ---
def extract_active_window(sequence, window_size=15):
    sequence = np.array(sequence)
    diffs = np.linalg.norm(np.diff(sequence, axis=0), axis=1)
    scores = np.convolve(diffs, np.ones(window_size), mode='valid')
    start_idx = np.argmax(scores)
    end_idx = start_idx + window_size
    return sequence[start_idx:end_idx]

# --- ì¼ì • ì‹œê°„ ë™ì•ˆ ì‹œí€€ìŠ¤ ìˆ˜ì§‘ (ë“±ë¡ / ì¸ì¦ ì‹œ) ---
def collect_sequence(duration=5):
    sequence = []
    start_time = time.time()
    while time.time() - start_time < duration:
        ret, frame = cap.read()
        if not ret: continue

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb)

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0]
            all_landmarks = np.array([[lm.x, lm.y, lm.z] for lm in landmarks.landmark])
            lips = np.array([all_landmarks[i] for i in LIPS_IDX_40])
            normalized = normalize_lips_3d(lips, all_landmarks)
            sequence.append(normalized.flatten())

        cv2.imshow("Webcam", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    return extract_active_window(sequence)

# --- ë‘ ì‹œí€€ìŠ¤ ê°„ DTW ê±°ë¦¬ ê³„ì‚° ---
def compare_dtw(seq1, seq2):
    distance, _ = fastdtw(seq1, seq2, dist=euclidean)
    return distance

# --- ë“±ë¡ëœ ì—¬ëŸ¬ ì‹œí€€ìŠ¤ì™€ì˜ í‰ê·  DTW ê±°ë¦¬ ê³„ì‚° ---
def compare_multiple_dtw(test_seq, registered_seqs):
    distances = [compare_dtw(reg_seq, test_seq) for reg_seq in registered_seqs]
    return np.mean(distances), distances

# --- ë“±ë¡ëœ ì‹œí€€ìŠ¤ ê¸°ë°˜ ì„ê³„ê°’ ê³„ì‚° (Mean + k*Std ë°©ì‹) ---
def calculate_threshold(seqs):
    pair_dists = [compare_dtw(seqs[i], seqs[j]) for i in range(len(seqs)) for j in range(i+1, len(seqs))]
    threshold = np.mean(pair_dists) + 1.5 * np.std(pair_dists)  # â† ì—¬ê¸°ì„œ 1.5 ì¡°ì • ê°€ëŠ¥
    print(f"ğŸ§  ìë™ ì„¤ì • ì„ê³„ê°’: {threshold:.2f} (mean + 1.5 * std)")
    return threshold

# --- MediaPipe ì´ˆê¸°í™” ---
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)
cap = cv2.VideoCapture(0)

# --- ì „ì—­ ë³€ìˆ˜ ---
registered_sequences = []
thresh = None
font = cv2.FONT_HERSHEY_SIMPLEX
MAX_REGISTER_COUNT = 3

# --- ë©”ì¸ ë£¨í”„ ---
while cap.isOpened():
    ret, frame = cap.read()
    if not ret: break

    h, w, _ = frame.shape
    display = frame.copy()
    key = cv2.waitKey(1) & 0xFF

    # ëœë“œë§ˆí¬ ì‹œê°í™”
    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb)

    if results.multi_face_landmarks:
        landmarks = results.multi_face_landmarks[0]
        all_landmarks = np.array([[lm.x, lm.y, lm.z] for lm in landmarks.landmark])
        lips = np.array([all_landmarks[i] for i in LIPS_IDX_40])
        normalized = normalize_lips_3d(lips, all_landmarks)

        # ì›ë³¸ í”„ë ˆì„ ìƒ ì‹œê°í™”
        for i in LIPS_IDX_40:
            x = int(landmarks.landmark[i].x * w)
            y = int(landmarks.landmark[i].y * h)
            cv2.circle(display, (x, y), 2, (255, 0, 0), -1)

        # ì •ê·œí™”ëœ ì…ìˆ  ì‹œê°í™” (ì™¼ìª½ ìƒë‹¨)
        anchor = (100, 100)
        scale = 80
        for pt in normalized:
            x = int(pt[0] * scale + anchor[0])
            y = int(pt[1] * scale + anchor[1])
            cv2.circle(display, (x, y), 2, (0, 0, 255), -1)

    # --- í‚¤ ì´ë²¤íŠ¸ ì²˜ë¦¬ ---
    if key == ord('r'):
        if len(registered_sequences) < MAX_REGISTER_COUNT:
            print(f"ğŸŸ¢ ë“±ë¡ ì‹œì‘ ({len(registered_sequences)+1}/{MAX_REGISTER_COUNT})")
            seq = collect_sequence()
            registered_sequences.append(seq)
            print("âœ… ë“±ë¡ ì™„ë£Œ")
            if len(registered_sequences) == MAX_REGISTER_COUNT:
                thresh = calculate_threshold(registered_sequences)
        else:
            print("â— ë“±ë¡ì€ ìµœëŒ€ 3íšŒê¹Œì§€ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ˆê¸°í™”í•˜ë ¤ë©´ 'C' í‚¤ë¥¼ ëˆ„ë¥´ì„¸ìš”.")

    elif key == ord('a'):
        print("ğŸŸ¡ ì¸ì¦ ì‹œì‘ (3ì´ˆ)")
        test_sequence = collect_sequence()
        if len(registered_sequences) == MAX_REGISTER_COUNT and thresh is not None:
            avg_dist, dists = compare_multiple_dtw(test_sequence, registered_sequences)
            print(f"ğŸ“ DTW ê±°ë¦¬ë“¤: {[round(d, 2) for d in dists]}")
            print(f"ğŸ“ í‰ê·  ê±°ë¦¬: {avg_dist:.2f} (ì„ê³„ê°’: {thresh:.2f})")

            if avg_dist <= thresh:
                cv2.putText(display, "PASS âœ…", (30, 60), font, 1.5, (0, 255, 0), 3)
            elif avg_dist <= thresh * 1.2:
                cv2.putText(display, "PASS (within 20%) âœ…", (30, 60), font, 1.5, (0, 200, 100), 3)
            else:
                cv2.putText(display, "FAIL âŒ", (30, 60), font, 1.5, (0, 0, 255), 3)
        else:
            print("âŒ ë“±ë¡ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë¨¼ì € ë“±ë¡ì„ ì™„ë£Œí•´ì£¼ì„¸ìš”.")

    elif key == ord('c'):
        registered_sequences = []
        thresh = None
        print("â™»ï¸ ë“±ë¡ ì´ˆê¸°í™” ì™„ë£Œ")

    elif key == ord('q'):
        break

    cv2.imshow("Webcam", display)

# --- ì¢…ë£Œ ---
cap.release()
cv2.destroyAllWindows()
