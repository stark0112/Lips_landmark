import os
import cv2
import numpy as np
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean
import mediapipe as mp
from sklearn.metrics import roc_curve, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

# --- ì„¤ì • ---
LIPS_IDX_40 = [61, 185, 40, 39, 37, 0, 267, 269, 270, 409,
               291, 375, 321, 405, 314, 17, 84, 181, 91, 146,
               78, 95, 88, 178, 87, 14, 317, 402, 318, 324,
               308, 415, 310, 311, 312, 13, 82, 81, 80, 191]
EYE_LEFT_IDX, EYE_RIGHT_IDX, NOSE_TIP_IDX = 33, 263, 1

ROOT = r"C:\\Users\\jyk\\Desktop\\LIP_SECURITY"
REGISTER_DIR = os.path.join(ROOT, "í”Œë ‰ì‹œìŠ¤í…Œë¼ë§ˆìž„(ê¹€ìž¬ì˜)", "train")
TEST_SETS = {
    "ê°™ì€ì‚¬ëžŒ_ê°™ì€ë‹¨ì–´": os.path.join(ROOT, "í”Œë ‰ì‹œìŠ¤í…Œë¼ë§ˆìž„(ê¹€ìž¬ì˜)", "test"),
    "ê°™ì€ì‚¬ëžŒ_ë‹¤ë¥¸ë‹¨ì–´": os.path.join(ROOT, "ì•ˆë“œë¡œì´ë“œë”¥ëŸ¬ë‹(ê¹€ìž¬ì˜)", "test"),
    "ë‹¤ë¥¸ì‚¬ëžŒ_ê°™ì€ë‹¨ì–´": os.path.join(ROOT, "í”Œë ‰ì‹œìŠ¤í…Œë¼ë§ˆìž„(ì˜¤ìž¬ë³µ)", "test"),
    "ë‹¤ë¥¸ì‚¬ëžŒ_ë‹¤ë¥¸ë‹¨ì–´": os.path.join(ROOT, "í…Œë¼ë§ˆìž„í™”ì´íŒ…(ì˜¤ìž¬ë³µ)", "test")
}

# --- ì´ˆê¸°í™” ---
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(refine_landmarks=True)

# --- ì •ê·œí™” í•¨ìˆ˜ ---
def normalize_lips_3d(points, ref_points):
    center = np.mean(points, axis=0)
    points -= center
    x_axis = points[10] - points[0]
    y_axis = points[29] - points[19]
    x_axis /= np.linalg.norm(x_axis)
    y_axis /= np.linalg.norm(y_axis)
    z_axis = np.cross(x_axis, y_axis); z_axis /= np.linalg.norm(z_axis)
    y_axis = np.cross(z_axis, x_axis); y_axis /= np.linalg.norm(y_axis); y_axis *= -1
    R = np.stack([x_axis, y_axis, z_axis], axis=1)
    points = points @ R
    eye_left, eye_right, nose = ref_points[EYE_LEFT_IDX], ref_points[EYE_RIGHT_IDX], ref_points[NOSE_TIP_IDX]
    scale = (np.linalg.norm(eye_left - eye_right) + np.linalg.norm(nose - (eye_left + eye_right) / 2)) / 2
    return points / scale if scale > 0 else points

# --- ì‹œí€€ìŠ¤ ì¶”ì¶œ ---
def extract_sequence_from_video(path, rotate=True, window_size=15):
    sequence = []
    cap = cv2.VideoCapture(path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        if rotate: frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)
        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = face_mesh.process(rgb)
        if results.multi_face_landmarks:
            lm = results.multi_face_landmarks[0].landmark
            all_landmarks = np.array([[p.x, p.y, p.z] for p in lm])
            lips = np.array([all_landmarks[i] for i in LIPS_IDX_40])
            normalized = normalize_lips_3d(lips, all_landmarks)
            sequence.append(normalized.flatten())
    cap.release()
    if len(sequence) < window_size: return None
    diffs = np.linalg.norm(np.diff(sequence, axis=0), axis=1)
    scores = np.convolve(diffs, np.ones(window_size), mode='valid')
    start = np.argmax(scores)
    return np.array(sequence[start:start+window_size])

# --- ê±°ë¦¬ ê³„ì‚° ---
def compare_dtw(seq1, seq2):
    dist, _ = fastdtw(seq1, seq2, dist=euclidean)
    return dist

# --- EER ê¸°ë°˜ ìž„ê³„ê°’ ê³„ì‚° ---
def get_eer_threshold(distances, labels):
    fpr, tpr, thresholds = roc_curve(labels, -np.array(distances))  # ìž‘ì„ìˆ˜ë¡ ìœ ì‚¬í•˜ë¯€ë¡œ ë¶€í˜¸ ë°˜ì „
    fnr = 1 - tpr
    eer_idx = np.argmin(np.abs(fpr - fnr))
    eer_thresh = -thresholds[eer_idx]  # ë¶€í˜¸ ë³µì›
    eer = fpr[eer_idx]

    # --- ì‹œê°í™” ---
    plt.plot(fpr, tpr, label='ROC Curve')
    plt.plot([0,1],[0,1],'--',alpha=0.3)
    plt.scatter(fpr[eer_idx], tpr[eer_idx], color='red', label=f"EER = {eer:.2f}")
    plt.title("ROC Curve & EER")
    plt.xlabel("False Positive Rate"); plt.ylabel("True Positive Rate")
    plt.legend(); plt.grid(True); plt.show()

    return eer_thresh, eer

# --- ë“±ë¡ ---
print("ðŸ“¥ ë“±ë¡ ì‹œìž‘")
registered_sequences = []
for f in sorted(os.listdir(REGISTER_DIR)):
    if f.endswith((".mp4", ".mov")):
        seq = extract_sequence_from_video(os.path.join(REGISTER_DIR, f))
        if seq is not None: registered_sequences.append(seq)
if len(registered_sequences) < 3:
    print("âŒ ë“±ë¡ ì‹¤íŒ¨: 3ê°œ ì´ìƒ í•„ìš”"); exit()

# --- í…ŒìŠ¤íŠ¸ ---
print("\nðŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼")
all_distances, all_labels = [], []

for label, test_path in TEST_SETS.items():
    print(f"\nðŸ“‚ {label}")
    is_positive = (label == "ê°™ì€ì‚¬ëžŒ_ê°™ì€ë‹¨ì–´")
    for f in sorted(os.listdir(test_path)):
        if not f.endswith(".mp4"): continue
        path = os.path.join(test_path, f)
        test_seq = extract_sequence_from_video(path)
        if test_seq is None:
            print(f"âš ï¸ {f} - ì‹œí€€ìŠ¤ ë¶€ì¡±"); continue
        dists = [compare_dtw(reg, test_seq) for reg in registered_sequences]
        avg = np.mean(dists)
        all_distances.append(avg)
        all_labels.append(1 if is_positive else 0)
        print(f"{f} â†’ í‰ê·  ê±°ë¦¬: {avg:.2f}")

# --- ì„±ëŠ¥ í‰ê°€ ---
eer_thresh, eer = get_eer_threshold(all_distances, all_labels)
y_pred = [1 if d <= eer_thresh else 0 for d in all_distances]

print(f"\nðŸ“ˆ EER Threshold: {eer_thresh:.2f} | EER: {eer:.3f}")
print("\nðŸ“Œ EER ê¸°ì¤€ ì„±ëŠ¥ ì§€í‘œ")
print(f"Accuracy : {accuracy_score(all_labels, y_pred):.2f}")
print(f"Precision: {precision_score(all_labels, y_pred):.2f}")
print(f"Recall   : {recall_score(all_labels, y_pred):.2f}")
print(f"F1 Score : {f1_score(all_labels, y_pred):.2f}")
